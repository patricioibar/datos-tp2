{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a80780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/06 12:54:47 WARN Utils: Your hostname, LENOVOID-ubuntu, resolves to a loopback address: 127.0.1.1; using 192.168.10.209 instead (on interface wlp2s0)\n",
      "25/10/06 12:54:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/06 12:54:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "# suprimir future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f6215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_int(some_value):\n",
    "    if some_value is None:\n",
    "        return None\n",
    "    try:\n",
    "        return int(some_value)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407d095",
   "metadata": {},
   "source": [
    "# Consultas propias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd81ae",
   "metadata": {},
   "source": [
    "### 1. Monto total recaudado por ventas de los 5 productos con más reseñas positivas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35545c",
   "metadata": {},
   "source": [
    "#### Hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577dcfaa",
   "metadata": {},
   "source": [
    "- Se considera que una reseña es positiva cuando el rating de la misma es mayor que 3.\n",
    "- Si una reseña tiene un valor nulo en el *rating*, no se considera.\n",
    "- Si un *order_item* tiene valor nulo en *line_total*, el valor puede ser inferido a través del precio unitario y la cantidad comprada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883549d3",
   "metadata": {},
   "source": [
    "#### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac39861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_reviews_columns(row: Row):\n",
    "    rating = 0 if row.rating is None else row.rating\n",
    "    return (\n",
    "        parse_to_int(row.product_id),\n",
    "        rating,\n",
    "    )\n",
    "    \n",
    "reviewsIdx = {\n",
    "    \"product_id\": 0,\n",
    "    \"rating\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d5c2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "reviews = sqlContext.read.csv(\n",
    "    'data/reviews.csv',\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "reviewsRDD = reviews.rdd.map(retain_reviews_columns).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a973849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_products_columns(row: Row):\n",
    "    product_name = \"UNDEFINED\" if row.product_name is None else row.product_name\n",
    "    brand = \"UNDEFINED\" if row.brand is None else row.brand\n",
    "    brand = brand.strip().upper()\n",
    "    return (\n",
    "        parse_to_int(row.product_id),\n",
    "        product_name,\n",
    "        brand,\n",
    "        parse_to_int(row.category_id),\n",
    "    )\n",
    "    \n",
    "productsIdx = {\n",
    "    \"id\": 0,\n",
    "    \"name\": 1,\n",
    "    \"brand\": 2,\n",
    "    \"category_id\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00030eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "products = sqlContext.read.csv(\n",
    "    'data/products.csv',\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "productsRDD = products.rdd.map(retain_products_columns).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85f8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_items_columns(row: Row):\n",
    "    qty = parse_to_int(row.quantity)\n",
    "    quantity = 0 if qty is None else qty\n",
    "    line_total = row.line_total if row.line_total is not None else infer_line_total(row)\n",
    "    return (\n",
    "        parse_to_int(row.product_id),\n",
    "        quantity,\n",
    "        line_total\n",
    "    )\n",
    "    \n",
    "def infer_line_total(row: Row):\n",
    "    u_price = parse_to_int(row.unit_price)\n",
    "    qty = parse_to_int(row.quantity)\n",
    "    if (\n",
    "        u_price is not None\n",
    "        and qty is not None\n",
    "    ):\n",
    "        return u_price * qty\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "itemsIdx = {\n",
    "    \"product_id\": 0,\n",
    "    \"quantity\": 1,\n",
    "    \"line_total\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d73be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = sqlContext.read.csv(\n",
    "    'data/order_items.csv',\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "itemsRDD = items.rdd.map(retain_items_columns).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c9b33d",
   "metadata": {},
   "source": [
    "#### Resolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d42e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/06 12:54:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , review_id, customer_id, product_id, rating, title, comment, is_verified_purchase, helpful_votes, created_at\n",
      " Schema: _c0, review_id, customer_id, product_id, rating, title, comment, is_verified_purchase, helpful_votes, created_at\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pat/Documents/GitHub/datos-tp2/data/reviews.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# no hay missing values en reviews.rating\n",
    "top_5_products = reviewsRDD.filter(lambda row: row[reviewsIdx[\"rating\"]] > 3) \\\n",
    "    .map(lambda row: (row[reviewsIdx[\"product_id\"]], 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .takeOrdered(5, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e6e6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/06 12:54:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , order_item_id, order_id, product_id, quantity, unit_price, line_total, discount_amount\n",
      " Schema: _c0, order_item_id, order_id, product_id, quantity, unit_price, line_total, discount_amount\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pat/Documents/GitHub/datos-tp2/data/order_items.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_5_products_ids = [prod[0] for prod in top_5_products]\n",
    "top_5_products_sells = itemsRDD.filter(lambda row: row[itemsIdx[\"product_id\"]] in top_5_products_ids) \\\n",
    "    .map(lambda row: (row[itemsIdx[\"product_id\"]], row[itemsIdx[\"line_total\"]])) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65692e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/06 12:55:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , product_id, product_name, category_id, brand, price, cost, stock_quantity, weight_kg, dimensions, description, is_active, created_at\n",
      " Schema: _c0, product_id, product_name, category_id, brand, price, cost, stock_quantity, weight_kg, dimensions, description, is_active, created_at\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pat/Documents/GitHub/datos-tp2/data/products.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_5_products_names = productsRDD.filter(lambda row: row[productsIdx[\"id\"]] in top_5_products_ids) \\\n",
    "    .map(lambda row: (row[productsIdx[\"id\"]], row[productsIdx[\"name\"]])) \\\n",
    "    .collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2732fb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 productos con más reseñas positivas y monto de sus ventas totales:\n",
      "Producto Fully-configurable high-level circuit: $8320.50\n",
      "Producto Persevering logistical help-desk: $12220.00\n",
      "Producto Innovative solution-oriented installation: $291.20\n",
      "Producto Seamless radical architecture: $13547.28\n",
      "Producto Robust cohesive utilization: $271.51\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 productos con más reseñas positivas y monto de sus ventas totales:\")\n",
    "for prod in top_5_products_sells:\n",
    "    print(f\"Producto {top_5_products_names[prod[0]]}: ${prod[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d282cf",
   "metadata": {},
   "source": [
    "### 2. Durante 2024 ¿Qué porcentaje de las órdenes `REFUNDED` fueron órdenes con descuento? ¿La mayoría eran de usuarios activos? ¿Qué segmento de usuario realizó la mayor cantidad de reembolsos? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32e654",
   "metadata": {},
   "source": [
    "#### Hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff79a3",
   "metadata": {},
   "source": [
    "- Si el valor del campo *discount_amount* en *orders* es nulo, se asume que la órden no tuvo descuento.\n",
    "- Si el usuario de una órden no está en la tabla de *customers*, se asume que no es usuario activo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d25f83",
   "metadata": {},
   "source": [
    "#### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f22c0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_dict = {}\n",
    "with open(\"status.txt\", \"r\") as f:\n",
    "    valid_statuses = [line.strip() for line in f.readlines()]\n",
    "    id = 0\n",
    "    for status in valid_statuses:\n",
    "        status_dict[status] = id\n",
    "        id += 1\n",
    "\n",
    "statuses = sc.broadcast(status_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3d7c5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def retain_orders_columns(row: Row):\n",
    "    id = parse_to_int(row.customer_id)\n",
    "    datetime = get_orders_datetime(row)\n",
    "    year = datetime.year if datetime is not None else None\n",
    "    status_str = \"UNDEFINED\" if row.status is None else row.status.strip().upper()\n",
    "    status = statuses.value[status_str]\n",
    "    discount = 0.0 if row.discount_amount is None else row.discount_amount\n",
    "    return (\n",
    "        id,\n",
    "        discount,\n",
    "        status,\n",
    "        year,\n",
    "    )\n",
    "    \n",
    "def get_orders_datetime(row: Row):\n",
    "    return pd.to_datetime(row.order_date, format=\"%Y-%m-%dT%H:%M:%S.%f\", errors=\"coerce\")\n",
    "    \n",
    "ordersIdx = {\n",
    "    \"customer_id\": 0,\n",
    "    \"discount_amount\": 1,\n",
    "    \"status\": 2,\n",
    "    \"year\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a067c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "orders = sqlContext.read.csv(\n",
    "    'data/orders.csv',\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "ordersRDD = orders.rdd.map(retain_orders_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f15af0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_dict = {}\n",
    "with open(\"segments.txt\", \"r\") as f:\n",
    "    valid_segments = [line.strip() for line in f.readlines()]\n",
    "    id = 0\n",
    "    for segments in valid_segments:\n",
    "        segments_dict[segments] = id\n",
    "        id += 1\n",
    "\n",
    "segments = sc.broadcast(segments_dict)\n",
    "\n",
    "segment_id_to_name = {v: k for k, v in segments_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53bebd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_customers_columns(row: Row):\n",
    "    id = parse_to_int(row.customer_id)\n",
    "    segment_str = \"UNDEFINED\" if row.customer_segment is None else row.customer_segment.strip().upper()\n",
    "    segment = segments.value[segment_str]\n",
    "    is_active = False if row.is_active is None else row.is_active\n",
    "    return (\n",
    "        id,\n",
    "        segment,\n",
    "        is_active,\n",
    "    )\n",
    "    \n",
    "customersIdx = {\n",
    "    \"id\": 0,\n",
    "    \"segment\": 1,\n",
    "    \"is_active\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d077924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = sqlContext.read.csv(\n",
    "    'data/customers.csv',\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "customersRDD = customers.rdd.map(retain_customers_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e8a81",
   "metadata": {},
   "source": [
    "#### Resolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0873b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_user_active_and_segment = ordersRDD \\\n",
    "    .filter(lambda row: row[ordersIdx[\"status\"]] == statuses.value[\"REFUNDED\"] and row[ordersIdx[\"year\"]] == 2024) \\\n",
    "    .map(lambda row: (row[ordersIdx[\"customer_id\"]], row)) \\\n",
    "    .leftOuterJoin(customersRDD.map(lambda row: (row[customersIdx[\"id\"]], row))) \\\n",
    "    .map(lambda row: (\n",
    "        row[1][0][ordersIdx[\"discount_amount\"]],\n",
    "        row[1][1][customersIdx[\"segment\"]] if row[1][1] is not None else \"UNDEFINED\",\n",
    "        row[1][1][customersIdx[\"is_active\"]] if row[1][1] is not None else False,\n",
    "    )).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9660064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/06 13:14:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , order_id, customer_id, order_date, status, payment_method, shipping_address, billing_address, discount_amount, tax_amount, shipping_cost, total_amount, currency, created_at, updated_at, subtotal\n",
      " Schema: _c0, order_id, customer_id, order_date, status, payment_method, shipping_address, billing_address, discount_amount, tax_amount, shipping_cost, total_amount, currency, created_at, updated_at, subtotal\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pat/Documents/GitHub/datos-tp2/data/orders.csv\n",
      "25/10/06 13:15:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , customer_id, email, first_name, last_name, phone, date_of_birth, gender, country, city, postal_code, address, registration_date, last_login, is_active, customer_segment, marketing_consent\n",
      " Schema: _c0, customer_id, email, first_name, last_name, phone, date_of_birth, gender, country, city, postal_code, address, registration_date, last_login, is_active, customer_segment, marketing_consent\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pat/Documents/GitHub/datos-tp2/data/customers.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "discount_total_and_active_users = orders_user_active_and_segment \\\n",
    "    .map(\n",
    "        lambda row: (\n",
    "            1 if row[0] > 0 else 0, # tiene descuento\n",
    "            1 if row[2] else 0, # es de usuario activo\n",
    "            1,  # ordenes totales\n",
    "        )\n",
    "    ).reduce(lambda a, b: (a[0] + b[0], a[1] + b[1], a[2] + b[2]))\n",
    "\n",
    "discount_refunded_orders_percentaje = (discount_total_and_active_users[0] / discount_total_and_active_users[2]) * 100\n",
    "active_user_percentaje = (discount_total_and_active_users[1] / discount_total_and_active_users[2]) * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "82a463af",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_refunded_segment = orders_user_active_and_segment \\\n",
    "    .map(lambda row: (row[1], 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .reduce(lambda a, b: a if a[1] > b[1] else b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d476bb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.21286097052695"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_user_percentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "09045586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El 21.29% de las órdenes REFUNDED durante 2024 fueron órdenes con descuento.\n",
      "La mayoría eran de usuarios activos.\n",
      "El segmento que más órdenes REFUNDED tuvo fue REGULAR con 7284 órdenes.\n"
     ]
    }
   ],
   "source": [
    "refunded_segment = segment_id_to_name[most_refunded_segment[0]]\n",
    "print(f\"El {discount_refunded_orders_percentaje:.2f}% de las órdenes REFUNDED durante 2024 fueron órdenes con descuento.\")\n",
    "print(\"La mayoría eran de usuarios activos.\" if active_user_percentaje > 50 else \"La mayoría no eran de usuarios activos.\")\n",
    "print(f\"El segmento que más órdenes REFUNDED tuvo fue {refunded_segment} con {most_refunded_segment[1]} órdenes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5413ad6",
   "metadata": {},
   "source": [
    "### 3. ¿Cuáles son las 3 marcas que vendieron menos unidades de productos durante 2025? Mostrar los nombres de los productos que más ingresos generaron de esas marcas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d7e43",
   "metadata": {},
   "source": [
    "#### Hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c500a3ab",
   "metadata": {},
   "source": [
    "- No se tienen en cuenta para este análisis las ventas cuyo producto no está registrado en la tabla de *products*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce440e39",
   "metadata": {},
   "source": [
    "#### Resolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcb1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_products_joined = itemsRDD \\\n",
    "    .map(\n",
    "        lambda row: (\n",
    "            row[itemsIdx[\"product_id\"]], \n",
    "            (row[itemsIdx[\"quantity\"]], row[itemsIdx[\"line_total\"]])\n",
    "        )\n",
    "    ).join(productsRDD.map( # como me interesa la información de marca, hago inner join\n",
    "        lambda row: (row[productsIdx[\"id\"]], (row[productsIdx[\"brand\"]]))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "less_sells_brands = items_products_joined.map(\n",
    "        lambda row: (\n",
    "            row[1][1], # brand\n",
    "            row[1][0][0], # quantity\n",
    "        )\n",
    "    ).reduceByKey(lambda a, b: a + b) \\\n",
    "    .takeOrdered(3, key=lambda x: x[1])\n",
    "less_sells_brands_names = [brand[0] for brand in less_sells_brands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_sells = itemsRDD.map(\n",
    "    lambda row: (row[itemsIdx[\"product_id\"]], row[itemsIdx[\"line_total\"]])\n",
    ").join(productsRDD.map(\n",
    "    lambda row: (row[productsIdx[\"id\"]], row[productsIdx[\"brand\"]]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_products_per_brand = brand_sells.filter(\n",
    "    lambda row: row[1][1] in less_sells_brands_names\n",
    ").map(\n",
    "    lambda row: ((row[1][1], row[0]), row[1][0])  # ((brand, product_id), line_total)\n",
    ").reduceByKey(lambda a, b: a + b) \\\n",
    ".map(\n",
    "    lambda row: (row[0][0], (row[0][1], row[1]))  # (brand, (product_id, total_line))\n",
    ").reduceByKey(lambda a, b: a if a[1] > b[1] else b) \\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_products_per_brand_ids = [prod[1][0] for prod in top_products_per_brand]\n",
    "top_products_per_brand_names = productsRDD.filter(\n",
    "    lambda row: row[productsIdx[\"id\"]] in top_products_per_brand_ids\n",
    ").map(\n",
    "    lambda row: (row[productsIdx[\"id\"]], row[productsIdx[\"name\"]])\n",
    ").collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e0274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las marcas con menos unidades vendidas en 2025 son:\n",
      " - APPLE: 4942 unidades vendidas\n",
      " - ASHLEY FURNITURE: 5132 unidades vendidas\n",
      " - CASTROL: 5135 unidades vendidas\n",
      "\n",
      "El producto más vendido de cada una de esas marcas es:\n",
      " - CASTROL: Grass-roots directional success  con $83496.97 en ventas\n",
      " - ASHLEY FURNITURE: Distributed interactive neural-net con $30814.72 en ventas\n",
      " - APPLE: FACE-TO-FACE TANGIBLE STRATEGY con $133905.24 en ventas\n"
     ]
    }
   ],
   "source": [
    "print(\"Las marcas con menos unidades vendidas en 2025 son:\")\n",
    "for brand, amount in less_sells_brands:\n",
    "    print(f\" - {brand}: {amount} unidades vendidas\")\n",
    "    \n",
    "print(\"\\nEl producto más vendido de cada una de esas marcas es:\")\n",
    "for row in top_products_per_brand:\n",
    "    brand = row[0]\n",
    "    product_id = row[1][0]\n",
    "    total_line = row[1][1]\n",
    "    product_name = top_products_per_brand_names[product_id]\n",
    "    print(f\" - {brand}: {product_name} con ${total_line:.2f} en ventas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842df33e",
   "metadata": {},
   "source": [
    "### 4. Rating promedio de los productos pertenecientes a la categoría más vendida durante 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61494880",
   "metadata": {},
   "source": [
    "#### Hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e022ac5b",
   "metadata": {},
   "source": [
    "#### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_categories_columns(row: Row):\n",
    "    id = parse_to_int(row.category_id)\n",
    "    name = \"UNDEFINED\" if row.category_name is None else row.category_name.strip().upper()\n",
    "    parent = \"UNDEFINED\" if row.parent_category is None else row.parent_category.strip().upper()\n",
    "    return (\n",
    "        id,\n",
    "        name,\n",
    "        parent\n",
    "    )\n",
    "    \n",
    "categoriesIdx = {\n",
    "    \"id\": 0,\n",
    "    \"name\": 1,\n",
    "    \"parent\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230bf59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sqlContext.read.csv(\n",
    "    'data/categories.csv',\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "categoriesRDD = categories.rdd.map(retain_categories_columns).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1d78a",
   "metadata": {},
   "source": [
    "#### Resolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_sells = itemsRDD.map(\n",
    "    lambda row: (row[itemsIdx[\"product_id\"]], row[itemsIdx[\"line_total\"]])\n",
    ").join(\n",
    "    productsRDD.filter(\n",
    "        lambda row: row[productsIdx[\"category_id\"]] is not None\n",
    "    ).map(\n",
    "        lambda row: (row[productsIdx[\"id\"]], row[productsIdx[\"category_id\"]])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a3806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "most_selled_category = category_sells.map(\n",
    "    lambda row: (row[1][1], row[1][0])  # (category_id, line_total)\n",
    ").reduceByKey(lambda a, b: a + b) \\\n",
    ".reduce(lambda a, b: a if a[1] > b[1] else b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0e482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/06 12:56:44 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , category_id, category_name, parent_category, created_at\n",
      " Schema: _c0, category_id, category_name, parent_category, created_at\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pat/Documents/GitHub/datos-tp2/data/categories.csv\n"
     ]
    }
   ],
   "source": [
    "most_selled_category_name = categoriesRDD.filter(\n",
    "    lambda row: row[categoriesIdx[\"id\"]] == most_selled_category[0]\n",
    ").first()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_products = productsRDD.filter(\n",
    "        lambda row: (\n",
    "            row[productsIdx[\"category_id\"]] is not None\n",
    "            and row[productsIdx[\"category_id\"]] == most_selled_category[0]\n",
    "        )\n",
    "    ).map(\n",
    "        lambda row: row[productsIdx[\"id\"]]\n",
    "    ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695004bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "category_mean_rating = reviewsRDD.filter(\n",
    "    lambda row: row[reviewsIdx[\"product_id\"]] in category_products\n",
    ").map(\n",
    "    lambda row: row[reviewsIdx[\"rating\"]]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2663565",
   "metadata": {},
   "source": [
    "### 5. Obtener los 3 productos `ELECTRONICS` con más movimientos por daños, y el promedio de cambios en la cantidad para los movimientos dañados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f7cb8",
   "metadata": {},
   "source": [
    "#### Hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106ca8d",
   "metadata": {},
   "source": [
    "#### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e28687",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasons_dict = {}\n",
    "with open(\"reasons.txt\", \"r\") as f:\n",
    "    reasons = [line.strip() for line in f.readlines()]\n",
    "    id = 0\n",
    "    for reason in reasons:\n",
    "        reasons_dict[reason] = id\n",
    "        id += 1\n",
    "\n",
    "reasons = sc.broadcast(reasons_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73289f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_inventory_columns(row: Row):\n",
    "    product_id = parse_to_int(row.product_id)\n",
    "    reason_str = \"UNDEFINED\" if row.reason is None else row.reason.strip().upper()\n",
    "    reason = reasons.value[reason_str]\n",
    "    quantity = parse_to_int(row.quantity_change)\n",
    "    return (\n",
    "        product_id,\n",
    "        reason,\n",
    "        0 if quantity is None else quantity,\n",
    "    )\n",
    "    \n",
    "inventoryIdx = {\n",
    "    \"product_id\": 0,\n",
    "    \"reason\": 1,\n",
    "    \"quantity\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = sqlContext.read.csv(\n",
    "    'data/inventory_logs.csv',\n",
    "    header=True, inferSchema=True\n",
    ")\n",
    "inventoryRDD = inventory.rdd.map(retain_inventory_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a533cd53",
   "metadata": {},
   "source": [
    "#### Resolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_categories_id = categoriesRDD.filter(\n",
    "    lambda row: row[categoriesIdx[\"parent\"]] == \"ELECTRONICS\"\n",
    ").map(\n",
    "    lambda row: row[categoriesIdx[\"id\"]]\n",
    ").collect()\n",
    "\n",
    "electronics_products_ids = productsRDD.filter(\n",
    "    lambda row: (\n",
    "        row[productsIdx[\"category_id\"]] is not None\n",
    "        and row[productsIdx[\"category_id\"]] in electronics_categories_id\n",
    "    )\n",
    ").map(\n",
    "    lambda row: row[productsIdx[\"id\"]]\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a73c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "damaged_movements = inventoryRDD.filter(\n",
    "    lambda row: row[inventoryIdx[\"reason\"]] == reasons.value[\"DAMAGE\"]\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "damaged_electronics_movements_by_product = damaged_movements \\\n",
    ".filter(lambda row: row[inventoryIdx[\"product_id\"]] in electronics_products_ids) \\\n",
    ".map(\n",
    "    lambda row:\n",
    "        (row[inventoryIdx[\"product_id\"]], (1, row[inventoryIdx[\"quantity\"]]))  # (product_id, (total, quantity_change))\n",
    ").reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798963c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/06 13:02:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , log_id, product_id, movement_type, quantity_change, reason, timestamp, reference_id, notes\n",
      " Schema: _c0, log_id, product_id, movement_type, quantity_change, reason, timestamp, reference_id, notes\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/pat/Documents/GitHub/datos-tp2/data/inventory_logs.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "most_damaged_products = damaged_electronics_movements_by_product \\\n",
    "    .takeOrdered(3, key=lambda x: -x[1][0])\n",
    "\n",
    "most_damaged_products_ids = [prod[0] for prod in most_damaged_products]\n",
    "\n",
    "most_damaged_products_names = productsRDD.filter(\n",
    "    lambda row: row[productsIdx[\"id\"]] in most_damaged_products_ids\n",
    ").map(\n",
    "    lambda row: (row[productsIdx[\"id\"]], row[productsIdx[\"name\"]])\n",
    ").collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "damaged_movements_quantity_mean = damaged_movements.map(\n",
    "    lambda row: row[inventoryIdx[\"quantity\"]]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 3 productos ELECTRONICS con más movimientos por daños son:\n",
      "ID\tTotal Movs.\tCambio tot. en Cant.\tNombre\n",
      "909144\t4\t\t349\t\t\tSelf-enabling discrete open system\n",
      "986689\t4\t\t327\t\t\tUNDEFINED\n",
      "969306\t4\t\t-647\t\t\tPre-emptive zero tolerance encryption\n",
      "\n",
      "El promedio de cambios en la cantidad para los movimientos dañados es de -0.00 unidades.\n"
     ]
    }
   ],
   "source": [
    "print(\"Los 3 productos ELECTRONICS con más movimientos por daños son:\")\n",
    "print(\"ID\\tTotal Movs.\\tCambio tot. en Cant.\\tNombre\")\n",
    "for prod in most_damaged_products:\n",
    "    product_id = prod[0]\n",
    "    total_damages = prod[1][0]\n",
    "    quantity_change = prod[1][1]\n",
    "    product_name = most_damaged_products_names[product_id].strip()\n",
    "    print(f\"{product_id}\\t{total_damages}\\t\\t{quantity_change}\\t\\t\\t{product_name}\")\n",
    "    \n",
    "print(f\"\\nEl promedio de cambios en la cantidad para los movimientos dañados es de {damaged_movements_quantity_mean:.2f} unidades.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
